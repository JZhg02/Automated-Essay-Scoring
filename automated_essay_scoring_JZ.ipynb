{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896d4c671be8a2eb",
   "metadata": {},
   "source": [
    "# Automated Essay Scoring\n",
    "Machine Learning Challenge by [Kaggle](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/overview)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "17605286808ffd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.414602Z",
     "start_time": "2024-05-24T14:03:22.713318Z"
    }
   },
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "1d2d03515cada84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.425722Z",
     "start_time": "2024-05-24T14:03:23.416609Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "215f3ae5c96b5259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.443872Z",
     "start_time": "2024-05-24T14:03:23.427731Z"
    }
   },
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   essay_id   17307 non-null  object\n",
      " 1   full_text  17307 non-null  object\n",
      " 2   score      17307 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 405.8+ KB\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "3625639a20e2f218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.461607Z",
     "start_time": "2024-05-24T14:03:23.446025Z"
    }
   },
   "source": [
    "df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              score\n",
       "count  17307.000000\n",
       "mean       2.948402\n",
       "std        1.044899\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        4.000000\n",
       "max        6.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.948402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.044899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "5c24d6d9d4d79a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.474795Z",
     "start_time": "2024-05-24T14:03:23.463783Z"
    }
   },
   "source": [
    "df.isna().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id     0\n",
       "full_text    0\n",
       "score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "6ba51b1f5da40cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.483418Z",
     "start_time": "2024-05-24T14:03:23.476816Z"
    }
   },
   "source": [
    "df['score'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "3    6280\n",
       "2    4723\n",
       "4    3926\n",
       "1    1252\n",
       "5     970\n",
       "6     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "159bac1f9adf9862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.496855Z",
     "start_time": "2024-05-24T14:03:23.484428Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='score'), df['score'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "ed932bf736b04213",
   "metadata": {},
   "source": [
    "## Evaluation using the Quadratic Weighted Kappa\n",
    "The quadratic weighted kappa (QWK) score ranges from -1 to 1. A score of 1 indicates perfect agreement between the predicted score and the true score. A score of 0 indicates the agreement is no better than random. A score of -1 indicates perfect disagreement between the predicted score and the true score."
   ]
  },
  {
   "cell_type": "code",
   "id": "4cd09d6f87aabce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:23.506715Z",
     "start_time": "2024-05-24T14:03:23.497893Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Computes the quadratic weighted kappa.\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(y_true), min(y_pred))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels=range(min_rating, max_rating + 1))\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "\n",
    "    expected_mat = np.outer(hist_true, hist_pred) / num_scored_items\n",
    "\n",
    "    weight_mat = np.zeros((num_ratings, num_ratings))\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            weight_mat[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)\n",
    "\n",
    "    kappa = 1.0 - (np.sum(weight_mat * conf_mat) / np.sum(weight_mat * expected_mat))\n",
    "    return kappa"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "f6c1bd03bf9a39a6",
   "metadata": {},
   "source": [
    "## Using CountVectorizer and TfidfTransformer from sklearn \n",
    "[Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a5cc65a3c82f9",
   "metadata": {},
   "source": [
    "*Simple Text Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a5c2871df835262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:26.828370Z",
     "start_time": "2024-05-24T14:03:23.508726Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train['full_text'])\n",
    "X_train_counts.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "b2fa5e48d4e06bf9",
   "metadata": {},
   "source": [
    "Literally a word count but with tokens/chunks of texts. "
   ]
  },
  {
   "cell_type": "code",
   "id": "ba287f1afabdc0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.025582Z",
     "start_time": "2024-05-24T14:03:26.829621Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "7029315d61c0f3eb",
   "metadata": {},
   "source": [
    "TfidfTransformer is used to convert the word count into a frequency matrix. We simply divide the number of word per document/data/observation by total number of this word in all documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "a12c62f439f9f21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.033260Z",
     "start_time": "2024-05-24T14:03:27.026592Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "bf9bf0b696e0cc3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.077282Z",
     "start_time": "2024-05-24T14:03:27.035482Z"
    }
   },
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "a13eeeafe6c41ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.800200Z",
     "start_time": "2024-05-24T14:03:27.081294Z"
    }
   },
   "source": [
    "X_new_counts = count_vect.transform(X_test['full_text'])\n",
    "X_new_counts"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "e1277c3cb4a257d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.825800Z",
     "start_time": "2024-05-24T14:03:27.801721Z"
    }
   },
   "source": [
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "X_new_tfidf"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "15d5cc0c0ca4d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.840553Z",
     "start_time": "2024-05-24T14:03:27.827819Z"
    }
   },
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "f456a92ba2ce56ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.854038Z",
     "start_time": "2024-05-24T14:03:27.842564Z"
    }
   },
   "source": [
    "pred_df = pd.DataFrame({'essay_id': X_test['essay_id'], 'full_text': X_test['full_text'], 'score': predicted})\n",
    "pred_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...      3\n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...      3\n",
       "733    0ba78ec  The face of Mars could not be created by alien...      3\n",
       "16885  f96c287  Many people belive that the face on Mars was c...      3\n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...      3\n",
       "...        ...                                                ...    ...\n",
       "16145  ee1d27b  How the author support his suggests that study...      3\n",
       "4229   3e7dd0b  In this aricle , the author its trying to you ...      3\n",
       "4313   3fdbec2  The Facial Action Coding System enables comput...      3\n",
       "934    0edee1b  Hello my name is Luke Bomberger and, welcome t...      3\n",
       "5058   4b34887  I am for the value of using this technology to...      3\n",
       "\n",
       "[3462 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16145</th>\n",
       "      <td>ee1d27b</td>\n",
       "      <td>How the author support his suggests that study...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>3e7dd0b</td>\n",
       "      <td>In this aricle , the author its trying to you ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>3fdbec2</td>\n",
       "      <td>The Facial Action Coding System enables comput...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0edee1b</td>\n",
       "      <td>Hello my name is Luke Bomberger and, welcome t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>4b34887</td>\n",
       "      <td>I am for the value of using this technology to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3462 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "f2f99efa3bc43a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.861045Z",
     "start_time": "2024-05-24T14:03:27.856049Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.3694396302715193\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "a73fca87a2ae1ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:27.874180Z",
     "start_time": "2024-05-24T14:03:27.863054Z"
    }
   },
   "source": [
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa: 0.034102332855281525\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "a0296b3d1dbd891a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:32.691015Z",
     "start_time": "2024-05-24T14:03:27.876274Z"
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train['full_text'], y_train)\n",
    "predicted = text_clf.predict(X_test['full_text'])\n",
    "\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")\n",
    "\n",
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4679376083188908\n",
      "Quadratic Weighted Kappa: 0.5708430116379231\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "a7121630",
   "metadata": {},
   "source": [
    "Not so bad, getting a score of 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c50cc3bea09e9",
   "metadata": {},
   "source": [
    "For my next steps: \n",
    "<br/>\n",
    "https://www.datacamp.com/blog/what-is-tokenization\n",
    "<br/>\n",
    "https://www.nltk.org\n",
    "<br/>\n",
    "https://www.nyckel.com/pretrained-classifiers/\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373697a",
   "metadata": {},
   "source": [
    "## Using [NLTK](https://www.nltk.org/)\n",
    "Following [NLP Tutorial for Text Classification in Python](https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e)\n",
    "<br/>\n",
    "Some [documentation](https://datascientest.com/nlp-word-embedding-word2vec) "
   ]
  },
  {
   "cell_type": "code",
   "id": "bb3c9d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:32.698735Z",
     "start_time": "2024-05-24T14:03:32.692342Z"
    }
   },
   "source": [
    "# Text preprocessing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# for word embedding*\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jacqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jacqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jacqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jacqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "e8eefdda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:03:32.711715Z",
     "start_time": "2024-05-24T14:03:32.700926Z"
    }
   },
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "0e0c5f88",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-24T14:03:32.713886Z"
    }
   },
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "X_train['clean_text'] = X_train['full_text'].apply(lambda x: finalpreprocess(x))\n",
    "X_train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "X_test['clean_text'] = X_test['full_text'].apply(lambda x: finalpreprocess(x))\n",
    "X_test.head()"
   ],
   "id": "d4550327a9079c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize the sentences\n",
    "X_train['clean_text_tok'] = X_train['clean_text'].apply(nltk.word_tokenize)\n",
    "X_test['clean_text_tok'] = X_test['clean_text'].apply(nltk.word_tokenize)"
   ],
   "id": "90aebc7c7ced21c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True) # WordVectorizer and TfidfTransformer in one model\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train['clean_text'])\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test['clean_text'])"
   ],
   "id": "f6fa07f95edaae91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#building Word2Vec model\n",
    "\n",
    "model = Word2Vec(sentences=X_train['clean_text_tok'], \n",
    "                 vector_size=100, \n",
    "                 window=5, \n",
    "                 min_count=1, \n",
    "                 workers=4\n",
    "                 )\n",
    "w2v = {word: vector for word, vector in zip(model.wv.index_to_key, model.wv.vectors)}\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0) for words in X\n",
    "        ])"
   ],
   "id": "5c80a3c9ad1023f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train['clean_text_tok'])\n",
    "X_test_vectors_w2v = modelw.transform(X_test['clean_text_tok'])"
   ],
   "id": "652e27059c7ad54f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-3, random_state=42,\n",
    "                    max_iter=5, tol=None)\n",
    "\n",
    "clf.fit(X_train_vectors_tfidf, y_train)\n",
    "predicted = clf.predict(X_test_vectors_tfidf)\n",
    "\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")\n",
    "\n",
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ],
   "id": "a2585e4db9907aa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NLP with [Keras pretrained models](https://keras.io/api/keras_nlp/models/#kerasnlp-models)",
   "id": "6a4cc949f096ebaf"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n",
    "backbone = keras_nlp.models.BertBackbone.from_preset(\"bert_tiny_en_uncased\")\n",
    "tokenizer = keras_nlp.models.BertTokenizer.from_preset(\"bert_tiny_en_uncased\")\n",
    "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\"bert_tiny_en_uncased\")"
   ],
   "id": "cb9baa810051eb02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pip install pipreqs\n",
    "pipreqs "
   ],
   "id": "8eff90da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
