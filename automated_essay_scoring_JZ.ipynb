{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896d4c671be8a2eb",
   "metadata": {},
   "source": [
    "# Automated Essay Scoring\n",
    "Machine Learning Challenge by [Kaggle](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.514192Z",
     "start_time": "2024-05-24T16:27:22.369990Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "17605286808ffd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1d2d03515cada84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\r\\n\\r\\nThis is a letter to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\r\\n\\r\\nThis is a letter to...      3"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "215f3ae5c96b5259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   essay_id   17307 non-null  object\n",
      " 1   full_text  17307 non-null  object\n",
      " 2   score      17307 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 405.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3625639a20e2f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.948402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.044899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  17307.000000\n",
       "mean       2.948402\n",
       "std        1.044899\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        4.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5c24d6d9d4d79a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id     0\n",
       "full_text    0\n",
       "score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6ba51b1f5da40cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "3    6280\n",
       "2    4723\n",
       "4    3926\n",
       "1    1252\n",
       "5     970\n",
       "6     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "159bac1f9adf9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='score'), df['score'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed932bf736b04213",
   "metadata": {},
   "source": [
    "## Evaluation using the Quadratic Weighted Kappa\n",
    "The quadratic weighted kappa (QWK) score ranges from -1 to 1. A score of 1 indicates perfect agreement between the predicted score and the true score. A score of 0 indicates the agreement is no better than random. A score of -1 indicates perfect disagreement between the predicted score and the true score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4cd09d6f87aabce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Computes the quadratic weighted kappa.\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(y_true), min(y_pred))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels=range(min_rating, max_rating + 1))\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "\n",
    "    expected_mat = np.outer(hist_true, hist_pred) / num_scored_items\n",
    "\n",
    "    weight_mat = np.zeros((num_ratings, num_ratings))\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            weight_mat[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)\n",
    "\n",
    "    kappa = 1.0 - (np.sum(weight_mat * conf_mat) / np.sum(weight_mat * expected_mat))\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1bd03bf9a39a6",
   "metadata": {},
   "source": [
    "## Using CountVectorizer and TfidfTransformer from sklearn \n",
    "[Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a5cc65a3c82f9",
   "metadata": {},
   "source": [
    "*Simple Text Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4a5c2871df835262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train['full_text'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa5e48d4e06bf9",
   "metadata": {},
   "source": [
    "Literally a word count but with tokens/chunks of texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ba287f1afabdc0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029315d61c0f3eb",
   "metadata": {},
   "source": [
    "TfidfTransformer is used to convert the word count into a frequency matrix. We simply divide the number of word per document/data/observation by total number of this word in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a12c62f439f9f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845,)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bf9bf0b696e0cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a13eeeafe6c41ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_counts = count_vect.transform(X_test['full_text'])\n",
    "X_new_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e1277c3cb4a257d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "X_new_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "15d5cc0c0ca4d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f456a92ba2ce56ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16145</th>\n",
       "      <td>ee1d27b</td>\n",
       "      <td>How the author support his suggests that study...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>3e7dd0b</td>\n",
       "      <td>In this aricle , the author its trying to you ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>3fdbec2</td>\n",
       "      <td>The Facial Action Coding System enables comput...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0edee1b</td>\n",
       "      <td>Hello my name is Luke Bomberger and, welcome t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>4b34887</td>\n",
       "      <td>I am for the value of using this technology to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3462 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...      3\n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...      3\n",
       "733    0ba78ec  The face of Mars could not be created by alien...      3\n",
       "16885  f96c287  Many people belive that the face on Mars was c...      3\n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...      3\n",
       "...        ...                                                ...    ...\n",
       "16145  ee1d27b  How the author support his suggests that study...      3\n",
       "4229   3e7dd0b  In this aricle , the author its trying to you ...      3\n",
       "4313   3fdbec2  The Facial Action Coding System enables comput...      3\n",
       "934    0edee1b  Hello my name is Luke Bomberger and, welcome t...      3\n",
       "5058   4b34887  I am for the value of using this technology to...      3\n",
       "\n",
       "[3462 rows x 3 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({'essay_id': X_test['essay_id'], 'full_text': X_test['full_text'], 'score': predicted})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f2f99efa3bc43a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.558518Z",
     "start_time": "2024-05-24T16:27:22.540245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.3694396302715193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a73fca87a2ae1ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.560528Z",
     "start_time": "2024-05-24T16:27:22.560380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa: 0.034102332855281525\n"
     ]
    }
   ],
   "source": [
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a0296b3d1dbd891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4679376083188908\n",
      "Quadratic Weighted Kappa: 0.5708430116379231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train['full_text'], y_train)\n",
    "predicted = text_clf.predict(X_test['full_text'])\n",
    "\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")\n",
    "\n",
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7121630",
   "metadata": {},
   "source": [
    "Not so bad, getting a score of 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c50cc3bea09e9",
   "metadata": {},
   "source": [
    "For my next steps: \n",
    "<br/>\n",
    "https://www.datacamp.com/blog/what-is-tokenization\n",
    "<br/>\n",
    "https://www.nltk.org\n",
    "<br/>\n",
    "https://www.nyckel.com/pretrained-classifiers/\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373697a",
   "metadata": {},
   "source": [
    "## Using [NLTK](https://www.nltk.org/)\n",
    "Following [NLP Tutorial for Text Classification in Python](https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e)\n",
    "<br/>\n",
    "Some [documentation](https://datascientest.com/nlp-word-embedding-word2vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bb3c9d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jacq/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jacq/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jacq/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jacq/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# for word embedding*\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e8eefdda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.622011Z",
     "start_time": "2024-05-24T16:27:22.600138Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0e0c5f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.690522Z",
     "start_time": "2024-05-24T16:27:22.676388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12931</th>\n",
       "      <td>be29f81</td>\n",
       "      <td>There is no question that the driverless car i...</td>\n",
       "      <td>question driverless car technological advancem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>be96267</td>\n",
       "      <td>I will be telling you about a story called \"A ...</td>\n",
       "      <td>tell story call cowboy rode wave think good st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>417a337</td>\n",
       "      <td>While driveless cars a cooler driving yourself...</td>\n",
       "      <td>driveless car cooler drive may bite safe every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>dcf3a1e</td>\n",
       "      <td>Dear State Senator,\\r\\n\\r\\nI do not like the E...</td>\n",
       "      <td>dear state senator like electoral college elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>9d04b4e</td>\n",
       "      <td>The \" Unmasking the Face on Mars\" was NOT crea...</td>\n",
       "      <td>unmask face mar create alien face mar natural ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  \\\n",
       "12931  be29f81  There is no question that the driverless car i...   \n",
       "12955  be96267  I will be telling you about a story called \"A ...   \n",
       "4410   417a337  While driveless cars a cooler driving yourself...   \n",
       "15013  dcf3a1e  Dear State Senator,\\r\\n\\r\\nI do not like the E...   \n",
       "10643  9d04b4e  The \" Unmasking the Face on Mars\" was NOT crea...   \n",
       "\n",
       "                                              clean_text  \n",
       "12931  question driverless car technological advancem...  \n",
       "12955  tell story call cowboy rode wave think good st...  \n",
       "4410   driveless car cooler drive may bite safe every...  \n",
       "15013  dear state senator like electoral college elec...  \n",
       "10643  unmask face mar create alien face mar natural ...  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "X_train['clean_text'] = X_train['full_text'].apply(lambda x: finalpreprocess(x))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d4550327a9079c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.730466Z",
     "start_time": "2024-05-24T16:27:22.716926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>people tend use car much basically live get da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>imagine top scientist nasa viking spacecraft s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>face mar could create alien land form create c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>many people belive face mar create alien alien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>driverless car come soon later people argue po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  \\\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...   \n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...   \n",
       "733    0ba78ec  The face of Mars could not be created by alien...   \n",
       "16885  f96c287  Many people belive that the face on Mars was c...   \n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...   \n",
       "\n",
       "                                              clean_text  \n",
       "12696  people tend use car much basically live get da...  \n",
       "4625   imagine top scientist nasa viking spacecraft s...  \n",
       "733    face mar could create alien land form create c...  \n",
       "16885  many people belive face mar create alien alien...  \n",
       "3334   driverless car come soon later people argue po...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['clean_text'] = X_test['full_text'].apply(lambda x: finalpreprocess(x))\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "90aebc7c7ced21c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.785179Z",
     "start_time": "2024-05-24T16:27:22.771746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "X_train['clean_text_tok'] = X_train['clean_text'].apply(nltk.word_tokenize)\n",
    "X_test['clean_text_tok'] = X_test['clean_text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7bec123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>people tend use car much basically live get da...</td>\n",
       "      <td>[people, tend, use, car, much, basically, live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>imagine top scientist nasa viking spacecraft s...</td>\n",
       "      <td>[imagine, top, scientist, nasa, viking, spacec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>face mar could create alien land form create c...</td>\n",
       "      <td>[face, mar, could, create, alien, land, form, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>many people belive face mar create alien alien...</td>\n",
       "      <td>[many, people, belive, face, mar, create, alie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>driverless car come soon later people argue po...</td>\n",
       "      <td>[driverless, car, come, soon, later, people, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  \\\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...   \n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...   \n",
       "733    0ba78ec  The face of Mars could not be created by alien...   \n",
       "16885  f96c287  Many people belive that the face on Mars was c...   \n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "12696  people tend use car much basically live get da...   \n",
       "4625   imagine top scientist nasa viking spacecraft s...   \n",
       "733    face mar could create alien land form create c...   \n",
       "16885  many people belive face mar create alien alien...   \n",
       "3334   driverless car come soon later people argue po...   \n",
       "\n",
       "                                          clean_text_tok  \n",
       "12696  [people, tend, use, car, much, basically, live...  \n",
       "4625   [imagine, top, scientist, nasa, viking, spacec...  \n",
       "733    [face, mar, could, create, alien, land, form, ...  \n",
       "16885  [many, people, belive, face, mar, create, alie...  \n",
       "3334   [driverless, car, come, soon, later, people, a...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f6fa07f95edaae91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.810767Z",
     "start_time": "2024-05-24T16:27:22.794767Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True) # WordVectorizer and TfidfTransformer in one model\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train['clean_text'])\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5c80a3c9ad1023f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:27:22.886369Z",
     "start_time": "2024-05-24T16:27:22.820299Z"
    }
   },
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "\n",
    "model = Word2Vec(sentences=X_train['clean_text_tok'], \n",
    "                 vector_size=100, \n",
    "                 window=5, \n",
    "                 min_count=1, \n",
    "                 workers=4\n",
    "                 )\n",
    "w2v = {word: vector for word, vector in zip(model.wv.index_to_key, model.wv.vectors)}\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0) for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "652e27059c7ad54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train['clean_text_tok'])\n",
    "X_test_vectors_w2v = modelw.transform(X_test['clean_text_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a2585e4db9907aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.45031773541305603\n",
      "Quadratic Weighted Kappa: 0.5574675462818004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-3, random_state=42,\n",
    "                    max_iter=5, tol=None)\n",
    "\n",
    "clf.fit(X_train_vectors_tfidf, y_train)\n",
    "predicted = clf.predict(X_test_vectors_tfidf)\n",
    "\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")\n",
    "\n",
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cc949f096ebaf",
   "metadata": {},
   "source": [
    "## NLP with [Keras pretrained models](https://keras.io/api/keras_nlp/models/#kerasnlp-models)\n",
    "\n",
    "[Bert Classifiers](https://keras.io/api/keras_nlp/models/bert/bert_classifier/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cb9baa810051eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp\n",
    "import tensorflow as tf\n",
    "\n",
    "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(\"bert_tiny_en_uncased\")\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased\", num_classes=7, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "291fe423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow dataset\n",
    "def dataframe_to_dataset(X, y):\n",
    "    df = X.copy()\n",
    "    df['labels'] = y\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df)))\n",
    "    return ds\n",
    "\n",
    "train_tf_dataset = dataframe_to_dataset(X_train[['clean_text']], y_train)\n",
    "test_tf_dataset = dataframe_to_dataset(X_test[['clean_text']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "48535e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('question driverless car technological advancement today society however importanat question yet completely answered question full use driverless car necessary technological advancement answer yes important question driverless car necessary technological advancement first reason infinite possibility taht driverless car offer would benefit society second reason safety driverless car could offer complete fully reason support driverless car could benefit society many way technological advancement driverless car necessary one would benefit society developmentment driverless car would offer infinite possiblities would provide many important benefit one benefit driver would ability rest relax may argue driver never rest relax wheel however driverless car completely develop wouldnt need driver car drive driver relaxes well alternative tire sriver also mention passage every car driverless transportation efficiency speed would excel every fleet car system transportation would efficient flawless common say computer make mistake matter circumstance course car driverless completely computerized system think car make mistake would result much high saftey think driver make mistake would result much high saftey common person would want high safety drive unsafe drive result driver mistake driver make mistake answer concern unsafe driving driverless car without doubt use driverless car would definitely safest way transportation possible clearly development driverless car one society great technological advancement question still remain devlopment driverless car necessary technological advancemnt answer question yet determine point certain people continue develop answer question fully answer answer question yes devlopment driverless car necessary use driverless car would provide infinite possibility today problemed transportation world also would provide maximum safety wh transportated transportation world technological advancement driverless car necessary one would benefit society', 4)\n"
     ]
    }
   ],
   "source": [
    "def get_texts_and_labels(X, y):\n",
    "    texts = X['clean_text'].tolist()\n",
    "    labels = y.tolist()\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = get_texts_and_labels(X_train[['clean_text']], y_train)\n",
    "test_texts, test_labels = get_texts_and_labels(X_test[['clean_text']], y_test)\n",
    "\n",
    "print((train_texts[0], train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "469eb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the texts \n",
    "# The preprocessor will tokenize the texts, and encode them into ids to map to the BERT vocabulary\n",
    "preprocessed_train_texts = preprocessor(train_texts)\n",
    "preprocessed_test_texts = preprocessor(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d6d49459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6923/6923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 105ms/step - loss: 1.1190 - sparse_categorical_accuracy: 0.5545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4255f3dc60>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=preprocessed_train_texts, y=train_labels, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "56c66b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716581193.512447  349193 service.cc:145] XLA service 0x7f438825d680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1716581193.514981  349193 service.cc:153]   StreamExecutor device (0): Host, Default Version\n",
      "2024-05-24 22:06:33.795496: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/6923\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:58:47\u001b[0m 11s/step - loss: 0.6054 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1716581199.672713  349193 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6923/6923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 91ms/step - loss: 0.8801 - sparse_categorical_accuracy: 0.6256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f42cdeb9f30>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    jit_compile=True,\n",
    ")\n",
    "classifier.fit(x=preprocessed_train_texts, y=train_labels, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "43dd639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1731/1731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.01515   , -2.5966995 , -1.4228523 , ...,  2.6925843 ,\n",
       "         0.9004487 , -2.8749375 ],\n",
       "       [-5.622581  , -2.668289  , -1.8633065 , ...,  2.8382761 ,\n",
       "         1.638929  , -1.840886  ],\n",
       "       [-7.6777434 , -1.1952523 ,  1.6521977 , ..., -0.02198903,\n",
       "        -3.3243122 , -5.6559286 ],\n",
       "       ...,\n",
       "       [-6.1243434 ,  1.3501959 ,  1.371524  , ..., -0.8509998 ,\n",
       "        -2.9880426 , -3.949362  ],\n",
       "       [-6.051654  ,  1.4242927 ,  3.19057   , ..., -2.1929855 ,\n",
       "        -3.2725418 , -4.083208  ],\n",
       "       [-6.790829  ,  0.6585024 ,  3.355659  , ..., -1.9247309 ,\n",
       "        -3.2917526 , -4.6624737 ]], dtype=float32)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(preprocessed_test_texts, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a907a5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4ad730c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5990756787983824\n",
      "Quadratic Weighted Kappa: 0.7629359037697089\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean(predicted_classes == y_test)}\")\n",
    "\n",
    "print(f\"Quadratic Weighted Kappa: {quadratic_weighted_kappa(y_test, predicted_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b0364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eff90da",
   "metadata": {},
   "source": [
    "pip install pipreqs\n",
    "pipreqs "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
