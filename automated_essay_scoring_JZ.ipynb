{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896d4c671be8a2eb",
   "metadata": {},
   "source": [
    "# Automated Essay Scoring\n",
    "Machine Learning Challenge by [Kaggle](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.119642Z",
     "start_time": "2024-05-20T19:00:59.115011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17605286808ffd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.710900Z",
     "start_time": "2024-05-20T19:00:59.260254Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2d03515cada84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.722823Z",
     "start_time": "2024-05-20T19:00:59.713923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\r\\n\\r\\nThis is a letter to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\r\\n\\r\\nThis is a letter to...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215f3ae5c96b5259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.742770Z",
     "start_time": "2024-05-20T19:00:59.723846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   essay_id   17307 non-null  object\n",
      " 1   full_text  17307 non-null  object\n",
      " 2   score      17307 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 405.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3625639a20e2f218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.757010Z",
     "start_time": "2024-05-20T19:00:59.744794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.948402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.044899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  17307.000000\n",
       "mean       2.948402\n",
       "std        1.044899\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        4.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c24d6d9d4d79a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.770968Z",
     "start_time": "2024-05-20T19:00:59.758036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id     0\n",
       "full_text    0\n",
       "score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba51b1f5da40cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.778714Z",
     "start_time": "2024-05-20T19:00:59.771975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "3    6280\n",
       "2    4723\n",
       "4    3926\n",
       "1    1252\n",
       "5     970\n",
       "6     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "159bac1f9adf9862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.793690Z",
     "start_time": "2024-05-20T19:00:59.780254Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='score'), df['score'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed932bf736b04213",
   "metadata": {},
   "source": [
    "## Evaluation using the Quadratic Weighted Kappa\n",
    "The quadratic weighted kappa (QWK) score ranges from -1 to 1. A score of 1 indicates perfect agreement between the predicted score and the true score. A score of 0 indicates the agreement is no better than random. A score of -1 indicates perfect disagreement between the predicted score and the true score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd09d6f87aabce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:00:59.802193Z",
     "start_time": "2024-05-20T19:00:59.795218Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Computes the quadratic weighted kappa.\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(y_true), min(y_pred))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels=range(min_rating, max_rating + 1))\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    hist_true = np.histogram(y_true, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "    hist_pred = np.histogram(y_pred, bins=np.arange(min_rating, max_rating + 2))[0]\n",
    "\n",
    "    expected_mat = np.outer(hist_true, hist_pred) / num_scored_items\n",
    "\n",
    "    weight_mat = np.zeros((num_ratings, num_ratings))\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            weight_mat[i, j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)\n",
    "\n",
    "    kappa = 1.0 - (np.sum(weight_mat * conf_mat) / np.sum(weight_mat * expected_mat))\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1bd03bf9a39a6",
   "metadata": {},
   "source": [
    "## Using CountVectorizer and TfidfTransformer from sklearn \n",
    "[Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a5cc65a3c82f9",
   "metadata": {},
   "source": [
    "*Simple Text Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a5c2871df835262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:02.646400Z",
     "start_time": "2024-05-20T19:00:59.804203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train['full_text'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa5e48d4e06bf9",
   "metadata": {},
   "source": [
    "Literally a word count but with tokens/chunks of texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba287f1afabdc0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:02.825533Z",
     "start_time": "2024-05-20T19:01:02.649836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 56588)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029315d61c0f3eb",
   "metadata": {},
   "source": [
    "TfidfTransformer is used to convert the word count into a frequency matrix. We simply divide the number of word per document/data/observation by total number of this word in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12c62f439f9f21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:02.833080Z",
     "start_time": "2024-05-20T19:01:02.827565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9bf0b696e0cc3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:02.881122Z",
     "start_time": "2024-05-20T19:01:02.834639Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13eeeafe6c41ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.606913Z",
     "start_time": "2024-05-20T19:01:02.882129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_counts = count_vect.transform(X_test['full_text'])\n",
    "X_new_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1277c3cb4a257d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.634268Z",
     "start_time": "2024-05-20T19:01:03.608919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3462x56588 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 564659 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "X_new_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d5cc0c0ca4d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.649569Z",
     "start_time": "2024-05-20T19:01:03.636274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f456a92ba2ce56ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.662334Z",
     "start_time": "2024-05-20T19:01:03.651574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>bb4c434</td>\n",
       "      <td>People tend to use there cars so much, they ba...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>44e88b0</td>\n",
       "      <td>Imagine being a top scientist at NASA and Viki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0ba78ec</td>\n",
       "      <td>The face of Mars could not be created by alien...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>f96c287</td>\n",
       "      <td>Many people belive that the face on Mars was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>317173f</td>\n",
       "      <td>Driverless Cars are coming soon or later? Peop...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16145</th>\n",
       "      <td>ee1d27b</td>\n",
       "      <td>How the author support his suggests that study...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>3e7dd0b</td>\n",
       "      <td>In this aricle , the author its trying to you ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>3fdbec2</td>\n",
       "      <td>The Facial Action Coding System enables comput...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0edee1b</td>\n",
       "      <td>Hello my name is Luke Bomberger and, welcome t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>4b34887</td>\n",
       "      <td>I am for the value of using this technology to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3462 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "12696  bb4c434  People tend to use there cars so much, they ba...      3\n",
       "4625   44e88b0  Imagine being a top scientist at NASA and Viki...      3\n",
       "733    0ba78ec  The face of Mars could not be created by alien...      3\n",
       "16885  f96c287  Many people belive that the face on Mars was c...      3\n",
       "3334   317173f  Driverless Cars are coming soon or later? Peop...      3\n",
       "...        ...                                                ...    ...\n",
       "16145  ee1d27b  How the author support his suggests that study...      3\n",
       "4229   3e7dd0b  In this aricle , the author its trying to you ...      3\n",
       "4313   3fdbec2  The Facial Action Coding System enables comput...      3\n",
       "934    0edee1b  Hello my name is Luke Bomberger and, welcome t...      3\n",
       "5058   4b34887  I am for the value of using this technology to...      3\n",
       "\n",
       "[3462 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({'essay_id': X_test['essay_id'], 'full_text': X_test['full_text'], 'score': predicted})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f99efa3bc43a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.669490Z",
     "start_time": "2024-05-20T19:01:03.664344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.3694396302715193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73fca87a2ae1ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:03.680644Z",
     "start_time": "2024-05-20T19:01:03.670579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa: 0.034102332855281525\n"
     ]
    }
   ],
   "source": [
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0296b3d1dbd891a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T19:01:07.683030Z",
     "start_time": "2024-05-20T19:01:03.682664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.4679376083188908\n",
      "Quadratic Weighted Kappa: 0.5708430116379231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train['full_text'], y_train)\n",
    "predicted = text_clf.predict(X_test['full_text'])\n",
    "\n",
    "print(f\"Mean: {np.mean(predicted == y_test)}\")\n",
    "\n",
    "kappa_score = quadratic_weighted_kappa(y_test, predicted)\n",
    "print(f\"Quadratic Weighted Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7121630",
   "metadata": {},
   "source": [
    "Not so bad, getting a score of 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c50cc3bea09e9",
   "metadata": {},
   "source": [
    "For my next steps: <br/>\n",
    "https://developer.ibm.com/tutorials/awb-tokenizing-text-in-python/\n",
    "<br/>\n",
    "https://medium.com/@bukowski.daniel/a-practical-framework-for-evaluating-text-generation-llms-4016ffa93736\n",
    "<br/>\n",
    "https://www.datacamp.com/blog/what-is-tokenization\n",
    "<br/>\n",
    "https://www.nltk.org\n",
    "<br/>\n",
    "https://www.nyckel.com/pretrained-classifiers/\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373697a",
   "metadata": {},
   "source": [
    "## Using [NLTK](https://www.nltk.org/)\n",
    "Following [NLP Tutorial for Text Classification in Python](https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb3c9d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jaczhang6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaczhang6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jaczhang6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jaczhang6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# for word embedding*\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8eefdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebadc798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12931    There is no question that the driverless car i...\n",
       "12955    I will be telling you about a story called \"A ...\n",
       "4410     While driveless cars a cooler driving yourself...\n",
       "15013    Dear State Senator,\\r\\n\\r\\nI do not like the E...\n",
       "10643    The \" Unmasking the Face on Mars\" was NOT crea...\n",
       "                               ...                        \n",
       "11284    1/27/15\\r\\n\\r\\nDear State senator,\\r\\n\\r\\nThe ...\n",
       "11964    May 19,1950 9:30 A.M.\\r\\n\\r\\n\"Wow, I Just had ...\n",
       "5390     In the article \"Driveless Cars Are Coming,\" th...\n",
       "860      The face on Mars is nothing but a Martian equi...\n",
       "15795    Computers and technology are evolving every ye...\n",
       "Name: full_text, Length: 13845, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e0c5f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12931</th>\n",
       "      <td>be29f81</td>\n",
       "      <td>There is no question that the driverless car i...</td>\n",
       "      <td>question driverless car technological advancem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>be96267</td>\n",
       "      <td>I will be telling you about a story called \"A ...</td>\n",
       "      <td>tell story call cowboy rode wave think good st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>417a337</td>\n",
       "      <td>While driveless cars a cooler driving yourself...</td>\n",
       "      <td>driveless car cooler drive may bite safe every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>dcf3a1e</td>\n",
       "      <td>Dear State Senator,\\r\\n\\r\\nI do not like the E...</td>\n",
       "      <td>dear state senator like electoral college elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10643</th>\n",
       "      <td>9d04b4e</td>\n",
       "      <td>The \" Unmasking the Face on Mars\" was NOT crea...</td>\n",
       "      <td>unmask face mar create alien face mar natural ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  \\\n",
       "12931  be29f81  There is no question that the driverless car i...   \n",
       "12955  be96267  I will be telling you about a story called \"A ...   \n",
       "4410   417a337  While driveless cars a cooler driving yourself...   \n",
       "15013  dcf3a1e  Dear State Senator,\\r\\n\\r\\nI do not like the E...   \n",
       "10643  9d04b4e  The \" Unmasking the Face on Mars\" was NOT crea...   \n",
       "\n",
       "                                              clean_text  \n",
       "12931  question driverless car technological advancem...  \n",
       "12955  tell story call cowboy rode wave think good st...  \n",
       "4410   driveless car cooler drive may bite safe every...  \n",
       "15013  dear state senator like electoral college elec...  \n",
       "10643  unmask face mar create alien face mar natural ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "X_train['clean_text'] = X_train['full_text'].apply(lambda x: finalpreprocess(x))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859b7f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65080f79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f82b75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eff90da",
   "metadata": {},
   "source": [
    "requirements.txt to add\n",
    "<br/>\n",
    "pip install scipy==1.11.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
